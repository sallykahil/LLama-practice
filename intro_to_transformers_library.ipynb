{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a631b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da426880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c09d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7befd51",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not load model cardiffnlp/twitter-roberta-base-sentiment-latest with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>, <class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'>). See the original errors:\n\nwhile loading with AutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 232, in load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 372, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4109, in from_pretrained\n    load_info = cls._load_pretrained_model(model, state_dict, checkpoint_files, load_config)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4226, in _load_pretrained_model\n    merged_state_dict.update(load_state_dict(ckpt_file))\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 341, in load_state_dict\n    check_torch_load_is_safe()\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1253, in check_torch_load_is_safe\n    raise ValueError(\nValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 248, in load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 372, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4109, in from_pretrained\n    load_info = cls._load_pretrained_model(model, state_dict, checkpoint_files, load_config)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4226, in _load_pretrained_model\n    merged_state_dict.update(load_state_dict(ckpt_file))\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 341, in load_state_dict\n    check_torch_load_is_safe()\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1253, in check_torch_load_is_safe\n    raise ValueError(\nValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n\nwhile loading with RobertaForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 232, in load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4109, in from_pretrained\n    load_info = cls._load_pretrained_model(model, state_dict, checkpoint_files, load_config)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4226, in _load_pretrained_model\n    merged_state_dict.update(load_state_dict(ckpt_file))\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 341, in load_state_dict\n    check_torch_load_is_safe()\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1253, in check_torch_load_is_safe\n    raise ValueError(\nValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 248, in load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4109, in from_pretrained\n    load_info = cls._load_pretrained_model(model, state_dict, checkpoint_files, load_config)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4226, in _load_pretrained_model\n    merged_state_dict.update(load_state_dict(ckpt_file))\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 341, in load_state_dict\n    check_torch_load_is_safe()\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1253, in check_torch_load_is_safe\n    raise ValueError(\nValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m pipe = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-classification\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcardiffnlp/twitter-roberta-base-sentiment-latest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:836\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m    834\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    835\u001b[39m     model_classes = targeted_task[\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m836\u001b[39m     model = \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m        \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    845\u001b[39m hub_kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = model.config._commit_hash\n\u001b[32m    847\u001b[39m \u001b[38;5;66;03m# Check which preprocessing classes the pipeline uses\u001b[39;00m\n\u001b[32m    848\u001b[39m \u001b[38;5;66;03m# None values indicate optional classes that the pipeline can run without, we don't raise errors if loading fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:268\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(model, config, model_classes, task, **model_kwargs)\u001b[39m\n\u001b[32m    266\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m class_name, trace \u001b[38;5;129;01min\u001b[39;00m all_traceback.items():\n\u001b[32m    267\u001b[39m             error += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwhile loading with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, an error is thrown:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    269\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with any of the following classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_tuple\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. See the original errors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    270\u001b[39m         )\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[31mValueError\u001b[39m: Could not load model cardiffnlp/twitter-roberta-base-sentiment-latest with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>, <class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'>). See the original errors:\n\nwhile loading with AutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 232, in load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 372, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4109, in from_pretrained\n    load_info = cls._load_pretrained_model(model, state_dict, checkpoint_files, load_config)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4226, in _load_pretrained_model\n    merged_state_dict.update(load_state_dict(ckpt_file))\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 341, in load_state_dict\n    check_torch_load_is_safe()\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1253, in check_torch_load_is_safe\n    raise ValueError(\nValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 248, in load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 372, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4109, in from_pretrained\n    load_info = cls._load_pretrained_model(model, state_dict, checkpoint_files, load_config)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4226, in _load_pretrained_model\n    merged_state_dict.update(load_state_dict(ckpt_file))\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 341, in load_state_dict\n    check_torch_load_is_safe()\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1253, in check_torch_load_is_safe\n    raise ValueError(\nValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n\nwhile loading with RobertaForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 232, in load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4109, in from_pretrained\n    load_info = cls._load_pretrained_model(model, state_dict, checkpoint_files, load_config)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4226, in _load_pretrained_model\n    merged_state_dict.update(load_state_dict(ckpt_file))\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 341, in load_state_dict\n    check_torch_load_is_safe()\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1253, in check_torch_load_is_safe\n    raise ValueError(\nValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 248, in load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4109, in from_pretrained\n    load_info = cls._load_pretrained_model(model, state_dict, checkpoint_files, load_config)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4226, in _load_pretrained_model\n    merged_state_dict.update(load_state_dict(ckpt_file))\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 341, in load_state_dict\n    check_torch_load_is_safe()\n  File \"c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1253, in check_torch_load_is_safe\n    raise ValueError(\nValueError: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\n\n\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acdd9974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2+cpu\n",
      "c:\\Users\\dell\\Desktop\\SALLY\\AI-Sally\\Intro-LLMs\\.venv\\Lib\\site-packages\\torch\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50aa5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(\"I love using transformers library!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
